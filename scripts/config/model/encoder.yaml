ACTIVATION: relu
MLP_HIDDEN_SIZES: [64, 64]
CNN_CHANNELS: [32, 32, 32]
CNN_KERNEL_SIZES:
  - [5, 5]
  - [3, 3]
  - [3, 3]
CNN_DENSE_SIZE: 64
ENCODER_TYPE: cnn
TRANSFORMER_PATCH_SIZE: 4
TRANSFORMER_LAYERS: 2
TRANSFORMER_HEADS: 4
TRANSFORMER_MLP_DIM: 128
TRANSFORMER_EMBED_DIM: 64

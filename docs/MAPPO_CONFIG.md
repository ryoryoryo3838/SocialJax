# MAPPO Config Guide

このドキュメントでは、`scripts/config/algorithm/mappo.yaml` に定義されているMAPPOアルゴリズムの設定項目について解説します。

## 設定項目一覧

| 項目名 | デフォルト値 | 説明 | 変更時の影響と調整の指針 |
| :--- | :--- | :--- | :--- |
| `name` | `mappo` | アルゴリズム名。 | 通常は変更しません。 |
| `NUM_ENVS` | `64` | 並列実行する環境数。 | **増やすと**: データの収集速度が上がり、学習が安定しやすくなりますが、VRAM/メモリ使用量が増加します。<br>**減らすと**: メモリ消費を抑えられますが、学習の収束が遅くなる可能性があります。 |
| `NUM_STEPS` | `5` | 1回の更新（Rollout）で収集する環境ごとのステップ数。 | **増やすと**: より長期的な報酬を考慮しやすくなりますが、更新頻度が下がります。RNNを使用する場合は系列長に関係します。<br>**減らすと**: 反応が早くなりますが、バイアスがかかりやすくなる場合があります。 |
| `TOTAL_TIMESTEPS` | `10000000` | 学習全体の総ステップ数。 | 学習にかかる総時間に直結します。タスクの難易度に応じて調整が必要です。 |
| `UPDATE_EPOCHS` | `2` | 収集したデータを用いて更新を繰り返す回数（PPOのエポック数）。 | **増やすと**: サンプル効率が上がりますが、やりすぎると過去のデータに過学習し、ポリシーが劣化（Collapse）するリスクがあります。<br>**目安**: 通常は2〜10程度です。 |
| `NUM_MINIBATCHES` | `16` | データをいくつのミニバッチに分割するか。 | **増やすと**: 1回の更新でのノイズが増え、局所解を脱しやすくなる可能性がありますが、計算効率が落ちる場合があります。<br>**減らすと**: 勾配推定が安定しますが、メモリ消費が増える可能性があります。 |
| `GAMMA` | `0.999` | 割引率（Discount Factor）。将来の報酬をどれくらい重視するか。 | **高い値 (0.99など)**: 長期的な視点で行動を学習します。遠い未来の報酬が重要になります。<br>**低い値 (0.90など)**: 直近の報酬を重視します。 |
| `GAE_LAMBDA` | `0.95` | GAE (Generalized Advantage Estimation) のパラメータ。 | バイアスとバリアンスのトレードオフを調整します。<br>**高い値**: バイアス低・バリアンス高。<br>**低い値**: バイアス高・バリアンス低。通常は0.95付近が推奨されます。 |
| `CLIP_EPS` | `0.2` | PPOのクリッピング範囲。ポリシーが大きく変化しすぎるのを防ぐためのパラメータ。 | **小さい値 (0.1)**: 学習が安定しますが、進みが遅くなる可能性があります。<br>**大きい値 (0.3以上)**: 学習が速くなる可能性がありますが、不安定になり、性能が急激に低下するリスクがあります。 |
| `ENT_COEF` | `0.01` | エントロピー係数。探索（Exploration）を促進するための項。 | **増やすと**: エージェントがランダムな行動を取りやすくなり、探索が促進されます。局所解に陥るのを防ぎます。<br>**減らすと**: 確定的な行動を取りやすくなります。学習終盤で収束させるために小さくすることもあります。 |
| `VF_COEF` | `0.5` | 価値関数の損失にかける係数。 | **注意**: 現在の実装（`components/algorithms/mappo.py`）では、ActorとCriticの更新が分離されているため、このパラメータは**実質的に使用されていない**可能性があります（通常は一つの損失関数にまとめる場合に使用されます）。 |
| `MAX_GRAD_NORM` | `0.5` | 勾配クリッピングの閾値。 | 勾配爆発を防ぎ、学習を安定させます。通常はこのまま使用します。 |
| `LR` | `0.0005` | 学習率（Learning Rate）。 | **最も重要なパラメータの一つです。**<br>**大きすぎる**: 学習が発散し、報酬が向上しません。<br>**小さすぎる**: 学習が非常に遅くなります。<br>学習がうまくいかない場合は、まずこの値を 1/10 または 10倍 にして試すのが定石です。 |
| `ANNEAL_LR` | `false` | 学習率の減衰（Linear Decay）を行うかどうか。 | `true`にすると、学習が進むにつれてLRが0に向かって直線的に減少します。学習終盤での安定化に寄与します。 |

## チェックポイント設定

| 項目名 | デフォルト値 | 説明 |
| :--- | :--- | :--- |
| `CHECKPOINT_DIR` | `mappo` | モデルの保存先ディレクトリ名。 |
| `CHECKPOINT_EVERY` | `100` | 保存頻度（更新ステップ数単位）。 |
| `CHECKPOINT_KEEP` | `3` | 保持する最新チェックポイントの数。これを超えると古いものから削除されます。 |

## チューニングのヒント

1. **学習が安定しない場合**:
   - `LR` を下げてみる（例: `0.0001`）。
   - `CLIP_EPS` を小さくする（例: `0.1`）。
   - `NUM_ENVS` を増やしてバッチサイズを大きくする。

2. **探索が足りない（局所解に陥っている）場合**:
   - `ENT_COEF` を上げる（例: `0.02`〜`0.05`）。
   - `NUM_STEPS` を増やして、より長いシーケンスを見るようにする。

3. **学習が遅い場合**:
   - `LR` を上げてみる（ただし不安定になるリスクあり）。
   - `NUM_ENVS` を増やしてデータ収集効率を上げる。

---
*このドキュメントは `scripts/config/algorithm/mappo.yaml` および `components/algorithms/mappo.py` の解析に基づいています。*
